\chapter{Introdução}

O processamento estatístico de sinais encontra aplicações nas
diversas áreas do conhecimento, desde medicina e saúde pública até
as bolsas de valores. Seu uso simplifica bastante as tarefas de
análise de dados e classificação, pois permite mapear os sinais em
um espaço onde as características discriminantes estão mais
evidentes.

Este trabalho descreve a aplicação das técnicas de processamento
estatístico para a extração de características relevantes de sinais
de um detector de partículas elementares de alta energia. As
características e padrões extraídos são utilizados para guiar o
processo de discriminação das partículas em um experimento de
colisão de partículas de alta taxa de eventos e com enorme volume de
dados produzidos.


\section{Contexto}

Com os constantes avanços tecnológicos dos sistemas eletrônicos de
aquisição de informações, é crescente a necessidade de técnicas
eficientes para o processamento \textit{online} de sinais. As
grandezas físicas são registradas por elementos sensores, que podem
ser únicos (como na medição da velocidade de um motor), ou
combinados aos milhares para obter o resultado final (como na
captura de vídeo e imagem digitais).

Em aplicações onde a fina granularidade da informação é necessária
para des\-cre\-ver adequadamente o processo físico em questão, e
sinais com alta dimensão são assim gerados por sistemas de medição
compostos por um número elevado de sensores, o custo computacional
geralmente é alto. Em alguns casos, a informação disponível pode
estar segmentada, pois foi produzida a partir de conjuntos de
sensores com características distintas.

Se há a necessidade de uma resposta rápida, pode ser utilizada a
combinação de técnicas de compactação de sinais e processamento
distribuído. O cenário pode ficar ainda mais complicado se o volume
de dados é alto e o problema a ser resolvido apresenta elevado grau
de complexidade.

O ambiente de aplicação deste trabalho é o sistema \textit{online}
de filtragem do ATLAS (\textit{A Toroidal LHC
Aparatus})~\cite{article:ATLAS:2008}, maior detector de propósito
geral do acelerador de partículas LHC (\textit{Large Hadron
Collider})~\cite{article:LHC:2008}. O LHC entrou em operação no
final de 2008, logo depois, passou por reparos no sistema de
resfriamento de um dos seus supercondutores, voltando a operar no
final de 2009.

No LHC, os sinais de interesse são raros, estão imersos em um
intenso ruído de fundo e a perda de um desses eventos compromete
severamente o desempenho dos detectores. Neste caso, é necessária
uma estratégia de filtragem capaz de remover, ou pelo menos atenuar
a intensidade do ruído sem perder os eventos de interesse.

Combinado a isso, a taxa de ocorrência de eventos é extremamente
elevada, fazendo com que o intervalo entre eventos consecutivos seja
extremamente pequeno. Considerando ainda que os detectores são
altamente segmentados e apresentam fina granularidade de células
detectoras, a quantidade de informação produzida é enorme. Neste
contexto, a seleção de eventos precisa ser realizada de modo
\textit{online} e sob severas restrições no tempo de processamento..

Técnicas que utilizam informações da estatística dos sinais, como
Análise de Componentes Principais (PCA - \textit{Principal Component
Analysis})~\cite{book:pca:2002}, Análise de Componentes
Independentes ICA (\textit{Independent Component Analysis})
\cite{book:oja:2001} e Redes Neurais Artificiais (RNA)
\cite{haykin:nn:2008}, são frequentemente utilizadas na solução de
problemas onde há a necessidade de processamento veloz, flexível e
eficiente.
%
%A Análise de Componentes Principais é uma técnica que utiliza
%informações da estatística de segunda ordem para obter uma
%transformação onde os sinais na nova base são ortogonais e estão nas
%direções de máxima variância do processo. Eliminando-se as
%componentes de menor energia (variância) pode-se compactar o sinal
%mantendo a maior parte da informação necessária para sua
%reconstrução.
%
%A Análise de Componentes Independentes  busca extrair
%características ocultas em um conjunto de sinais, utilizando para
%isso informações da estatística de ordem superior. As
%características encontradas podem ser utilizadas para discriminação
%de classes de sinais diferentes ou para facilitar a análise da
%informação.

%As Redes Neurais Artificiais \cite{haykin:nn:2008} têm um campo de
%aplicação bastante amplo em processamento de sinais. Podem ser
%utilizadas, por exemplo, em reconhecimento de padrões, classificação
%e filtragem não linear. As informações da estatística de ordem
%superior são utilizadas implicitamente através do uso de funções de
%ativação não lineares. As RNA podem utilizar treinamento
%supervisionado ou não-supervisionado.

\section{Motivação}

Desde o final do século 19, quando foi descoberto o elétron, o
estudo da física de partículas elementares, ou simplesmente física
de partículas, teve um crescimento acentuado. Na década de 1950, com
o uso dos aceleradores, foram descobertas centenas de novas
partículas. A física de partículas de altas energias pretende
encontrar os componentes fundamentais da matéria e descrever suas
formas de interação.

O acelerador de partículas LHC \cite{article:LHC:2008} é um
experimento construído no CERN (Organização Européia para Pesquisa
Nuclear) que entrou em operação no segundo semestre de 2008. Ao
operar na máxima capacidade, produzirá uma taxa de eventos que
chegará a 40MHz. Entretanto, as assinaturas de interesse ocorrerão
com uma freqüência muito baixa, o que faz do sistema de filtragem
\textit{online} um componente fundamental para os detectores.

O detector ATLAS \cite{article:ATLAS:2008} é um experimento de
propósito geral e está posicionado em um dos pontos de colisão do
LHC. Entre os principais objetivos do ATLAS, pode-se destacar a
busca pela partícula conhecida como \textit{bóson de Higgs}, que
segundo estudos teóricos seria responsável por interagir com as
partículas fornecendo-lhes massa \cite{livro:fisica1:2006}. A
partícula de Higgs ainda não foi verificada experimentalmente.

Parcela importante das informações necessárias para a caracterização
dos eventos é obtida do sistema de calorímetros, que é subdividido
em 7 camadas, sendo que 4 foram projetadas para as partículas
eletromagnéticas e 3 para as hadrônicas. Os calorímetros são, na
verdade, medidores de energia compostos por um grande número de
sensores (células). As células dos calorímetros quantificam a
energia perdida pelas partículas incidentes ao interagirem com o
material do detector. Para a caracterização do tipo de partícula
usa-se informação do perfil de deposição de energia nas camadas do
calorímetro.

%Algumas delas são instáveis e apenas existem por um curto período de
%tempo, sendo rapidamente transformadas em outras menos energéticas.

%Operando em máxima capacidade o LHC irá colidir feixes de prótons a
%cada 25 ns. Numa colisão uma quantidade enorme de energia será
%transformada em um grande número de partículas. A maior parte da
%informação a ser gerada já foi visualizada em experimentos
%anteriores, não sendo relevante para os detectores do LHC. A chamada
%nova física, ou física de interesse, representa uma pequena parcela
%das informações produzidas. Os eventos da física de interesse devem
%ser armazenados para futura análise detalhada. Percebe-se, então, a
%importância do sistema \textit{online} de filtragem e classificação,
%que deve ser capaz de identificar os eventos de interesse dentro do
%intenso ruído de fundo. Uma eficiente filtragem \textit{online}
%permite o processo de busca e análise \textit{offline}.

Os objetivos principais do sistema de filtragem \textit{online} em
experimentos de físicas de altas energias são maximizar a
probabilidade de detecção (e consequente armazenamento) dos eventos
de interesse, e minimizar a probabilidade de armazenar eventos não
desejados (ruído de fundo). Em um ambiente como este, a grande
dimensão dos dados, o intenso ruído de fundo e o curto tempo de
resposta exigido dos detectores e sistemas de filtragem são sérios
entraves para o processamento e classificação \textit{online} de
eventos.

No ATLAS, o sistema \textit{online} de filtragem (\textit{trigger})
de eventos é composto por três níveis, esperando-se armazenar, em
mídia permanente, uma taxa máxima de 200 Hz \cite{LI:ATLAS:1992}.
Considerando que a freqüência dos eventos é 40 MHz, deve haver uma
redução de $2\times 10^5$ vezes. O primeiro nível (L1 -
\textit{Level-One}), por restrições de tempo de resposta e
quantidade de informação a ser processada, foi implementado em
\textit{hardware} dedicado, objetivando reduzir a taxa de eventos
para 10kHz. Este nível opera com latência menor que $2,5\mu s$. O
segundo nível (L2 - \textit{Level-Two}) e o filtro de eventos (EF -
\textit{Event Filter}) correspondem à filtragem de alto nível (HLT -
\textit{high level trigger}) e, em conjunto, precisam reduzir de
10kHz para 200Hz a freqüência dos eventos. Devido à latência um
pouco maior, da ordem de $10ms$ para o segundo nível e alguns
segundos para o filtro de eventos, essas etapas serão realizadas em
\textit{software} através de um sistema de processamento
distribuído, que utiliza centenas de processadores semelhantes aos
de computadores pessoais (PC). Algoritmos desenvolvidos pela
colaboração do ATLAS estão prontos para operar nos diversos canais e
níveis de filtragem existentes.

No contexto dos diversos canais de interesse para a física no ATLAS,
este trabalho se encontra focado na discriminação elétron/jato
(e$^-/$j). Os elétrons com alto momento transverso são parte de
algumas das assinaturas mais prováveis do bóson de Higgs. Porém, em
termos de calorimetria, alguns jatos podem apresentar um perfil de
deposição de energia semelhante ao dos elétrons. Portanto, os jatos
representam ruído de fundo no processo de identificação de elétrons.
Apenas uma reduzida parcela dos candidatos a elétrons aceitos pelo
primeiro nível serão realmente elétrons; cabendo à filtragem de alto
nível reduzir ainda mais o ruído de fundo sem perder assinaturas de
interesse.

Considerando a alta taxa de eventos e a intensidade do ruído de
fundo produzidos pelo LHC, a busca por algoritmos de filtragem
\textit{online} mais eficientes se configura numa tarefa importante.
Uma redução no número de eventos não relevantes (ruído de fundo)
armazenados em mídia permanente significa uma maior eficiência na
análise \textit{offline} dos eventos de interesse e uma redução do
espaço (mídia) necessário para armazenamento.

Neste trabalho estão sendo propostas alternativas para o algoritmo
padrão de identificação de elétrons em uso atualmente no segundo
nível de filtragem do detector ATLAS. Os algoritmos desenvolvidos
apresentam maior eficiência de discriminação e tempo de
processamento dentro das restrições do LVL2.

...

Quando o LHC estiver operando em alta luminosidade, será comum o
efeito de empilhamento (do inglês \textit{pile-up}), ocasionado por
uma sobreposição de eventos na mesma região do detector. Ou seja, um
evento que ainda se desenvolve tem seu padrão de deposição de
energia distorcido por um novo que chega e se sobrepõe, gerando um
ruído de fundo que pode atingir grande intensidade. Os algoritmos de
filtragem devem apresentar bom desempenho mesmo quando o
empilhamento for frequente.



A cada evento, regiões diferentes do calorímetro são sensibilizadas,
essas áreas são denominadas regiões de interesse (RoI -
\textit{Region of Interest}). O primeiro nível fornece para o
segundo nível a localização primária das RoI.

Na Figura \ref{esquem} são mostradas as etapas envolvidas no
processo de filtragem no HLT. Inicialmente, os sinais dos
calorímetros, que são compostos pelas leituras das células sensoras
(de todas as sete camadas) que pertencem à RoI marcada pelo LVL1,
são selecionados. Uma RoI típica é descrita por cerca de 700 células
sensoras.

\begin{figure}[t!]
\centering
\includegraphics[width=14cm]{cap1_esquema}
\caption{Diagrama das etapas envolvidas no processo de discriminação
elétron/jato.} \label{esquem}
\end{figure}

%falar sobre as roi (procurar no artigo)

Em seguida as técnicas de extração de características tentam obter
informa\-ções relevantes do conjunto de sinais e que serão
utilizadas para o teste de hipótese e conseqüente decisão
elétron/jato.


\section{Objetivos}

Considerando os desafios existentes no ambiente de filtragem
\textit{online} do \linebreak ATLAS, onde os sinais são adquiridos
com fina segmentação, estão imersos em intenso ruído de fundo e as
assinaturas de interesse são raras, técnicas avançadas de extração
de características podem ser utilizadas para melhorar a eficiência
de classificação.

O principal objetivo deste trabalho é propor novos algoritmos para
extração de características na filtragem de alto nível do ATLAS no
canal elétron/jato. O trabalho será concentrado no desenvolvimento
de algoritmos para os sinais de calorimetria.

Serão utilizadas técnicas avançadas de processamento estatístico de
sinais, onde os principais desafios são a diminuição do tempo de
processamento e a maximização da eficiência dos classificadores.

Os sistemas discriminadores propostos serão comparados em termos da
eficiência global de discriminação e, também, considerando os
diversos parâmetros de interesse para a física.

\section{Metodologia}

O projeto e teste dos discriminadores de partículas foram realizados
a partir de um conjunto de eventos simulados. Estas simulações
consideram todas as características físicas do detector e do
acelerador. Os eventos simulados possuem rótulos de classe gerados
pelos simuladores, ou seja, sabe-se a priori qual a classe da
partícula que produziu cada um dos perfis de deposição de energia.

Foram utilizados também conjuntos de dados experimentais obtidos na
fase inicial de operação do LHC. Além dos jatos, sabe-se também que
os raios cósmicos representam ruído de fundo para o experimento,
então, os algoritmos propostos foram testados para uma base de dados
composta de eventos de raios cósmicos. Uma outra análise utilizou
eventos adquiridos durante o primeiro ciclo de operação
(\textit{run}) do LHC no final de 2009.

\section{Conteúdo do trabalho}

No Capítulo 2 será apresentado o ambiente científico no qual o
trabalho está sendo desenvolvido, contextualizando o detector de
partículas ATLAS, o acelerador LHC e o CERN. Uma descrição detalhada
do sistema de \textit{trigger} também será apresentada.

No Capítulo 3 serão mostrados os fundamentos teóricos das técnicas
de extração de características e teste de hipótese que serão
utilizadas para a otimização do sistema de filtragem do ATLAS.

Os resultados obtidos serão apresentadas no Capítulo~4. As
conclusões e os futuros trabalhos são os tópicos abordados no
Capítulo~5.

Nos Apêndices A e B são fornecidas as bases matemáticas para uma
melhor compreensão das técnicas estatística de processamento de
sinais descritas no Capítulo~3.
